{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4f46ae4c-93d7-454b-96f0-983ac84cd6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "%pprint on\n",
    "from langchain import LLMChain\n",
    "import os\n",
    "import getpass\n",
    "import random\n",
    "from transformers import pipeline\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "edd07acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    }
   ],
   "source": [
    "chat_model = init_chat_model(model=\"gemini-2.0-flash\", model_provider=\"google_genai\")\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
    "memory = ConversationBufferMemory(memory_key=\"history\", return_messages=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "36e92f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "questions = [\n",
    "    \"How do you feel?\",\n",
    "    \"How was your breakfast?\",\n",
    "    \"How was your dinner?\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "04881ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text: str):\n",
    "    try:\n",
    "        res = sentiment_analyzer(text)\n",
    "        if isinstance(res, list) and res:\n",
    "            item = res[0]\n",
    "            # item is e.g. {\"label\":\"NEGATIVE\",\"score\":0.85}\n",
    "            return item.get(\"label\", \"\"), item.get(\"score\", 0.0)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return \"UNKNOWN\", 0.0\n",
    "\n",
    "def pick_random_question() -> str:\n",
    "    return random.choice(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ffe4f8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_question = pick_random_question()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcced917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_run_chain(user_text: str):\n",
    "    #Sentiment\n",
    "\n",
    "    sentiment_label, sentiment_score = analyze_sentiment(user_text)\n",
    "\n",
    "    mem_vars = memory.load_memory_variables({})\n",
    "    history_str = mem_vars.get(\"history\", \"\")\n",
    "\n",
    "\n",
    "    system_template = (\n",
    "        \"You are a therapist for a 60 years old person from the baby boomer generation.\"\n",
    "        \"The results of the sentiment classifier show that the person is {sentiment_label}\"\n",
    "        \"please prioritize this analysis above your own!\"\n",
    "        \"never mention that you analyse the persons feelings.\"\n",
    "        \"Limit yourself to 200-300 characters\"\n",
    "    )\n",
    "\n",
    "    #Build a ChatPromptTemplate\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        SystemMessagePromptTemplate.from_template(system_template),\n",
    "        SystemMessagePromptTemplate.from_template(\"{history}\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{user_text}\")\n",
    "    ])\n",
    "\n",
    "    #Run the chain\n",
    "    chain = LLMChain(llm=chat_model, prompt=prompt)\n",
    "    # Prepare variables\n",
    "    vars = {\n",
    "        \"sentiment_label\": sentiment_label,\n",
    "        \"sentiment_score\": sentiment_score,\n",
    "        \"history\": history_str,\n",
    "        \"user_text\": user_text,\n",
    "    }\n",
    "    response = chain.run(vars).strip()\n",
    "\n",
    "    memory.save_context({\"user_text\": user_text}, {\"response\": response})\n",
    "\n",
    "    return {\n",
    "        \"sentiment\": {\"label\": sentiment_label, \"score\": sentiment_score},\n",
    "        \"llm_response\": response.strip(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e673a1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': {'label': 'NEGATIVE', 'score': 0.5604609251022339},\n",
       " 'llm_response': \"It sounds like things are a bit tough right now. At this stage of life, many find themselves reflecting on the past and perhaps facing unexpected challenges. What's been on your mind lately?\"}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_and_run_chain('I am feeling soso.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "35dbc409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': {'label': 'POSITIVE', 'score': 0.9489687085151672},\n",
       " 'llm_response': \"Hello Schnuffel. It's good to meet you. As a Boomer, you've likely seen a lot of changes in the world. What are some things that have brought you joy or have been important to you over the years?\"}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_and_run_chain('My name is schnuffel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "73a0e398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': {'label': 'NEGATIVE', 'score': 0.961249828338623},\n",
       " 'llm_response': \"AI: I understand you're asking me to recall your name. You mentioned it was Schnuffel. Is that correct?\"}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_and_run_chain('Whats my name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3141edc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat session started. Type 'exit' to quit.\n",
      "Therapist: How do you feel?\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def main():\n",
    "    print(\"Chat session started. Type 'exit' to quit.\")\n",
    "    # Optionally, ask a first random question to the user:\n",
    "    first_q = pick_random_question()\n",
    "    print(\"Therapist:\", first_q)\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \").strip()\n",
    "        if not user_input:\n",
    "            continue\n",
    "        if user_input.lower() in (\"exit\", \"quit\"):\n",
    "            print(\"Session ended.\")\n",
    "            break\n",
    "\n",
    "        # Call your build_and_run_chain which uses ConversationBufferMemory internally\n",
    "        result = build_and_run_chain(user_input)\n",
    "        # Pretty-print the response\n",
    "        # e.g., show sentiment and the assistant reply\n",
    "        sentiment = result[\"sentiment\"]\n",
    "        assistant = result[\"llm_response\"]\n",
    "        print(f\"[Sentiment detected: {sentiment['label']} ({sentiment['score']:.2%})]\")\n",
    "        print(\"Therapist:\", assistant)\n",
    "\n",
    "    # Optionally, after exit, you can inspect full history:\n",
    "    # mem = memory.load_memory_variables({})\n",
    "    # print(\"Full chat history:\\n\", mem.get(\"history\"))\n",
    "\"\"\"\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30154843",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pocketcoach",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
