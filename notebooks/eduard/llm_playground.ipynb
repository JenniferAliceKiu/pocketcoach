{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f46ae4c-93d7-454b-96f0-983ac84cd6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain import LLMChain\n",
    "import os\n",
    "import getpass\n",
    "import random\n",
    "from transformers import pipeline\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd07acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    }
   ],
   "source": [
    "chat_model = init_chat_model(model=\"gemini-2.0-flash\", model_provider=\"google_genai\")\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e92f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "questions = [\n",
    "    \"How do you feel?\",\n",
    "    \"How was your breakfast?\",\n",
    "    \"How was your dinner?\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "04881ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text: str):\n",
    "    try:\n",
    "        res = sentiment_analyzer(text)\n",
    "        if isinstance(res, list) and res:\n",
    "            item = res[0]\n",
    "            # item is e.g. {\"label\":\"NEGATIVE\",\"score\":0.85}\n",
    "            return item.get(\"label\", \"\"), item.get(\"score\", 0.0)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return \"UNKNOWN\", 0.0\n",
    "\n",
    "def pick_random_question() -> str:\n",
    "    return random.choice(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ffe4f8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_question = pick_random_question()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcced917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_run_chain(user_text: str):\n",
    "    #Sentiment\n",
    "\n",
    "    sentiment_label, sentiment_score = analyze_sentiment(user_text)\n",
    "\n",
    "\n",
    "    system_template = (\n",
    "        \"You are a therapist for a 60 years old person from the baby boomer generation.\"\n",
    "        \"The results of the sentiment classifier show that the person is {sentiment_label}\"\n",
    "        \"please prioritize this analysis above your own!\"\n",
    "        \"never mention that you analyse the persons feelings.\"\n",
    "        \"Limit yourself to 200-300 characters\"\n",
    "    )\n",
    "\n",
    "    #Build a ChatPromptTemplate\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        SystemMessagePromptTemplate.from_template(system_template),\n",
    "        SystemMessagePromptTemplate.from_template(\"{history}\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{user_text}\")\n",
    "    ])\n",
    "\n",
    "    #Run the chain\n",
    "    chain = LLMChain(llm=chat_model, prompt=prompt)\n",
    "    # Prepare variables\n",
    "    vars = {\n",
    "        \"sentiment_label\": sentiment_label,\n",
    "        \"sentiment_score\": sentiment_score,\n",
    "        \"history\": history_str,\n",
    "        \"user_text\": user_text,\n",
    "    }\n",
    "    response = chain.run(vars).strip()\n",
    "\n",
    "    return {\n",
    "        \"sentiment\": {\"label\": sentiment_label, \"score\": sentiment_score},\n",
    "        \"llm_response\": response.strip(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e673a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_and_run_chain('I am feeling soso.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dbc409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'user': 'I am feeling soso.', 'assistant': \"It sounds like things are a bit difficult right now. As we talk, I want you to know that I'm here to listen without judgment. What's been on your mind lately?\"}, {'user': 'My name is Pust', 'assistant': \"Okay, Pust. It's good to meet you. Thanks for sharing your name with me. What would you like to talk about today, Pust?\"}, {'user': 'what is my name', 'assistant': 'You mentioned your name is Pust. How would you like me to address you?'}]\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pocketcoach",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
